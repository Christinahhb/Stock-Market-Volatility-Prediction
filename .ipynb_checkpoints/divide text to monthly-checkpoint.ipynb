{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0232748e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存: C:\\Users\\22749\\Desktop\\UoG\\Fintech\\Dissertation\\Data\\News\\monthly\\1_April_2022.txt\n",
      "保存: C:\\Users\\22749\\Desktop\\UoG\\Fintech\\Dissertation\\Data\\News\\monthly\\29_April_2022.txt\n",
      "保存: C:\\Users\\22749\\Desktop\\UoG\\Fintech\\Dissertation\\Data\\News\\monthly\\22_September_2022.txt\n",
      "保存: C:\\Users\\22749\\Desktop\\UoG\\Fintech\\Dissertation\\Data\\News\\monthly\\4_November_2022.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "# 定义函数以从RTF文件中提取文本\n",
    "def extract_text_from_rtf(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    return content\n",
    "\n",
    "# 提取给定RTF文件中的文本\n",
    "file_path = 'C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/factiva/USA TODAY202204-11.rtf'\n",
    "rtf_content = extract_text_from_rtf(file_path)\n",
    "\n",
    "# 定义函数按月份分割文本\n",
    "def split_text_by_months(rtf_content):\n",
    "    # 移除RTF特定的标签并提取纯文本\n",
    "    plain_text = re.sub(r'\\\\[a-z]+\\d*', '', rtf_content)\n",
    "    plain_text = re.sub(r'{\\\\[^{}]*}', '', plain_text)\n",
    "    plain_text = re.sub(r'{|}', '', plain_text)\n",
    "    \n",
    "    # 按月份分割文本\n",
    "    months = re.split(r'(\\d{1,2} \\w+ 2022)', plain_text)\n",
    "    \n",
    "    # 创建一个字典来存储每个月的文本\n",
    "    month_texts = {}\n",
    "    current_month = ''\n",
    "    for part in months:\n",
    "        if re.match(r'\\d{1,2} \\w+ 2022', part):\n",
    "            current_month = part\n",
    "            month_texts[current_month] = ''\n",
    "        else:\n",
    "            if current_month in month_texts:\n",
    "                month_texts[current_month] += part\n",
    "    \n",
    "    return month_texts\n",
    "\n",
    "# 分割文本并按月份存储\n",
    "month_texts = split_text_by_months(rtf_content)\n",
    "\n",
    "# 指定保存文件的路径\n",
    "save_path = 'C:\\\\Users\\\\22749\\\\Desktop\\\\UoG\\\\Fintech\\\\Dissertation\\\\Data\\\\News\\\\monthly'\n",
    "\n",
    "# 确保保存路径存在，如果不存在则创建\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# 保存每个月的文本到单独的文件\n",
    "for month, text in month_texts.items():\n",
    "    # 将月份中的空格替换为下划线，以便用作文件名\n",
    "    month_filename = month.replace(' ', '_')\n",
    "    file_name = os.path.join(save_path, f'{month_filename}.txt')\n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)\n",
    "    \n",
    "    print(f'保存: {file_name}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4026d880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text has been cleaned and saved to 'cleaned_file.txt'.\n",
      "  USA Today Online  USATONL  English  Copyright \\'00\\'A9 2022 USA Today Online. Provided by ProQuest Information and Learning. All rights reserved.    U.S. employers added a booming 431,000 jobs in March as tumbling   COVID-19   cases more than offset concerns about soaring inflation and the war in Ukraine.   The unemployment rate fell from 3.8% to 3.6%, the Labor Department said Friday. That puts it just above the 50-year low of 3.5% just before the pandemic upended the economy in March 2020.   Economists surveyed by Bloomberg had estimated that 440,000 jobs were added last month.   The economy has now added more than 400,000 jobs a month for 11 months, the longest such streak on record,  Morgan Stanley  noted in a report.   President Joe Biden touted the drop in unemployment \\'20\\'13 down from 6.4% when he entered office \\'20\\'13 as the \\'20\\'1Cfastest decline in unemployment to start a president\\'20\\'19s term ever recorded.\\'20\\'1D   Of course,   COVID-19   created a massive gap in the labor   market  , creating significant room for recovery.   The nation has recouped 20.4 million,   or   93%, of the 22 million jobs lost early in the health crisis, leaving it 1.6 million jobs short of its pre-pandemic level, a gap that could be closed by summer.   'I LET MONEY GET IN THE WAY':Most recent job quitters have regrets   JUST HOW DIVERSE IS   FINANCE  ?:A Black college student's quest offers glimpse   Another positive: Payroll additions for January and February were revised up by 92,000. The upgrades pushed January's advance to 504,000 despite widespread omicron-related worker absences.   \"The labor   market   still has strong positive momentum and is making rapid progress towards pre-pandemic health,\" economist Rubeela Farooqi of High Frequency Economics wrote in a note to clients.   Favorable labor   market  , strong wages   The drop in unemployment came even as the number of people working   or   looking for jobs grew by 418,000, pushing the labor force participation rate from 62.3% to 62.4%, the highest since March 2020. More people who had been fearful of   COVID-19 or   staying home caring for children, among others, are returning to a favorable labor   market   with rising wages.   The number of people who couldn't look for work because of the pandemic fell to 874,000 from 1.2 million in February, Labor said,   Last month, leisure and hospitality, which includes restaurants and bars, the sector hit hardest by the pandemic, led the job gains with 112,000; professional and business services added 102,000; retail, 49,000; manufacturing, 38,000; and construction, 19,000.   Farooqi, among other economists, said the strong report bolsters the Federal Reserve's case for a half percentage point interest rate increase in May in an effort to curtail inflation. That would be the largest increase in more than two decades.   Several forces appeared to set the stage for more robust payroll gains in March. Persistent worker shortages likely spurred companies to pull forward their normal spring hiring sprees to get a jump on the competition, says  Goldman Sachs  economist Spencer Hill.   And new   COVID-19   cases have plunged to less than 30,000 a day from more than 1 million a day as omicron raged in January. That\\'20\\'19s encouraging more Americans to dine out and travel. It's also prodding people on the sidelines, to return to a worker-friendly labor   market   with near-record job openings and sharply rising wages.   Inflation drags down confidence   At the same time, inflation that hit 40-year highs each of the past several months \\'20\\'13 particularly soaring gasoline prices \\'20\\'13 have dampened business confidence. In February, a measure of small business optimism fell to the lowest level in more than a year, according to the  National Federation of Independent Business .   Some manufacturing workers are switching jobs as they seek shorter commutes to cope with high pump prices, says  Peter Quigley , CEO of  Kelly Services , a staffing firm.   Relief at the pump? What is the strategic petroleum reserve? Biden hopes it can bring down high gas prices   Food recall: Skippy peanut butter recall: Select products recalled because may contain steel fragments   \\'20\\'1CWe expect job creation will settle into a slower pace later this year as the economy feels the pinch from soaring inflation and tighter   financial   conditions,\\'20\\'1D economist Lydia Boussour wrote in a note to clients.   The Ukraine war and the   market volatility   it has triggered also \\'20\\'1Cmight have temporarily hit hiring plans,\\'20\\'1D says economist Andrew Hunter of Capital Economics.   But Tom Gimbel, CEO of LaSalle Network, a staffing firm, says \"more CEOs and CFOs are concerned about inflation\" than the war.   Omicron's BA.2 subvariant also could slow the pace of hiring in coming months, says economist Thomas Feltmate of TD Economics.   Some labor   market   gauges had raised concerns that job growth might already be downshifting. The number of small businesses open, as well as the numbers of employees working and hours they worked, all dipped in March, though they were still up sharply from January, according to Homebase, which provides payroll software to small firms.   \n"
     ]
    }
   ],
   "source": [
    "# Load the provided text file for processing\n",
    "file_path = 'C:\\\\Users\\\\22749\\\\Desktop\\\\UoG\\\\Fintech\\\\Dissertation\\\\Data\\\\News\\\\monthly\\\\1_April_2022.txt'  # Replace with your file path\n",
    "\n",
    "# Read the entire text from the file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text_content = file.read()\n",
    "\n",
    "# Define the text segments to remove\n",
    "text_to_remove_start = \"Contributing:\"\n",
    "text_to_remove_end = \"All rights reserved.\"\n",
    "\n",
    "new_str = text_to_remove_end.join(text_content.split(text_to_remove_end)[1:])\n",
    "new_str = text_to_remove_start.join(text_content.split(text_to_remove_start)[:1])\n",
    "# Save the cleaned text back to a file or use it as needed\n",
    "with open('C:\\\\Users\\\\22749\\\\Desktop\\\\UoG\\\\Fintech\\\\Dissertation\\\\Data\\\\News\\\\monthly\\\\cleaned_file.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(cleaned_text)\n",
    "\n",
    "# Output confirmation\n",
    "print(\"Text has been cleaned and saved to 'cleaned_file.txt'.\")\n",
    "print(new_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e8c4696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存: C:\\Users\\22749\\Desktop\\UoG\\Fintech\\Dissertation\\Data\\News\\monthly\\April_2022.txt\n",
      "保存: C:\\Users\\22749\\Desktop\\UoG\\Fintech\\Dissertation\\Data\\News\\monthly\\A9_2022.txt\n",
      "保存: C:\\Users\\22749\\Desktop\\UoG\\Fintech\\Dissertation\\Data\\News\\monthly\\September_2022.txt\n",
      "保存: C:\\Users\\22749\\Desktop\\UoG\\Fintech\\Dissertation\\Data\\News\\monthly\\Gannett_2022.txt\n",
      "保存: C:\\Users\\22749\\Desktop\\UoG\\Fintech\\Dissertation\\Data\\News\\monthly\\November_2022.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "# 定义函数以从RTF文件中提取文本\n",
    "def extract_text_from_rtf(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    return content\n",
    "\n",
    "# 提取给定RTF文件中的文本\n",
    "file_path = 'C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/factiva/USA TODAY202204-11.rtf'\n",
    "rtf_content = extract_text_from_rtf(file_path)\n",
    "\n",
    "# 定义函数按月份分割文本\n",
    "def split_text_by_months(rtf_content):\n",
    "    # 移除RTF特定的标签并提取纯文本\n",
    "    plain_text = re.sub(r'\\\\[a-z]+\\d*', '', rtf_content)\n",
    "    plain_text = re.sub(r'{\\\\[^{}]*}', '', plain_text)\n",
    "    plain_text = re.sub(r'{|}', '', plain_text)\n",
    "    \n",
    "    # 按月份分割文本\n",
    "    months = re.split(r'(\\w+ 2022)', plain_text)\n",
    "    \n",
    "    # 创建一个字典来存储每个月的文本\n",
    "    month_texts = {}\n",
    "    current_month = ''  # 初始化current_month以确保其具有值\n",
    "    for part in months:\n",
    "        match = re.match(r'(\\w+ 2022)', part)\n",
    "        if match:\n",
    "            current_month = match.group(1)  # 指定匹配的月份为current_month\n",
    "        else:\n",
    "            if current_month:  # 仅在current_month非空时添加文本\n",
    "                if current_month in month_texts:\n",
    "                    month_texts[current_month] += part\n",
    "                else:\n",
    "                    month_texts[current_month] = part\n",
    "    \n",
    "    return month_texts\n",
    "\n",
    "# 分割文本并按月份存储\n",
    "month_texts = split_text_by_months(rtf_content)\n",
    "\n",
    "# 指定保存文件的路径\n",
    "save_path = 'C:\\\\Users\\\\22749\\\\Desktop\\\\UoG\\\\Fintech\\\\Dissertation\\\\Data\\\\News\\\\monthly'\n",
    "\n",
    "# 确保保存路径存在，如果不存在则创建\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# 保存每个月的文本到单独的文件\n",
    "for month, text in month_texts.items():\n",
    "    month_filename = month.replace(' ', '_')\n",
    "    file_name = os.path.join(save_path, f'{month_filename}.txt')\n",
    "    with open(file_name, 'a', encoding='utf-8') as file:  # 使用 'a' 模式以追加到文件\n",
    "        file.write(text)\n",
    "    \n",
    "    print(f'保存: {file_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bdaf3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存: C:\\Users\\22749\\Desktop\\UoG\\Fintech\\Dissertation\\Data\\News\\January_2022.txt\n",
      "保存: C:\\Users\\22749\\Desktop\\UoG\\Fintech\\Dissertation\\Data\\News\\February_2022.txt\n",
      "保存: C:\\Users\\22749\\Desktop\\UoG\\Fintech\\Dissertation\\Data\\News\\March_2022.txt\n",
      "保存: C:\\Users\\22749\\Desktop\\UoG\\Fintech\\Dissertation\\Data\\News\\April_2022.txt\n",
      "保存: C:\\Users\\22749\\Desktop\\UoG\\Fintech\\Dissertation\\Data\\News\\November_2022.txt\n",
      "保存: C:\\Users\\22749\\Desktop\\UoG\\Fintech\\Dissertation\\Data\\News\\May_2022.txt\n",
      "保存: C:\\Users\\22749\\Desktop\\UoG\\Fintech\\Dissertation\\Data\\News\\June_2022.txt\n",
      "保存: C:\\Users\\22749\\Desktop\\UoG\\Fintech\\Dissertation\\Data\\News\\July_2022.txt\n",
      "保存: C:\\Users\\22749\\Desktop\\UoG\\Fintech\\Dissertation\\Data\\News\\August_2022.txt\n",
      "保存: C:\\Users\\22749\\Desktop\\UoG\\Fintech\\Dissertation\\Data\\News\\September_2022.txt\n",
      "保存: C:\\Users\\22749\\Desktop\\UoG\\Fintech\\Dissertation\\Data\\News\\October_2022.txt\n",
      "保存: C:\\Users\\22749\\Desktop\\UoG\\Fintech\\Dissertation\\Data\\News\\December_2022.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "def extract_text_from_rtf(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    return content\n",
    "\n",
    "file_path = 'C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/factiva/Factiva-01July20242101.rtf'\n",
    "rtf_content = extract_text_from_rtf(file_path)\n",
    "\n",
    "def split_text_by_months(rtf_content):\n",
    "    # Remove RTF tags to extract plain text\n",
    "    plain_text = re.sub(r'\\\\[a-z]+\\d*', '', rtf_content)\n",
    "    plain_text = re.sub(r'{\\\\[^{}]*}', '', plain_text)\n",
    "    plain_text = re.sub(r'{|}', '', plain_text)\n",
    "\n",
    "    # Regular expression to identify month and year correctly\n",
    "    months = re.split(r'\\b(January|February|March|April|May|June|July|August|September|October|November|December)\\s+2022\\b', plain_text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Store texts by month\n",
    "    month_texts = {}\n",
    "    current_month = ''\n",
    "    for i, part in enumerate(months):\n",
    "        if i % 2 == 1:  # This ensures we are on the month capturing group\n",
    "            current_month = part\n",
    "        else:\n",
    "            if current_month:\n",
    "                month_texts[current_month] = month_texts.get(current_month, '') + part\n",
    "\n",
    "    return month_texts\n",
    "\n",
    "month_texts = split_text_by_months(rtf_content)\n",
    "\n",
    "save_path = 'C:\\\\Users\\\\22749\\\\Desktop\\\\UoG\\\\Fintech\\\\Dissertation\\\\Data\\\\News'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "for month, text in month_texts.items():\n",
    "    month_filename = month.replace(' ', '_') + '_2022.txt'\n",
    "    file_name = os.path.join(save_path, month_filename)\n",
    "    with open(file_name, 'a', encoding='utf-8') as file:\n",
    "        file.write(text)\n",
    "    \n",
    "    print(f'保存: {file_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d6ca6774",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Copyright'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32100\\3699512444.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mdate_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mmonth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_month_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mmonth_year_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{month} {year}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmonth_year_key\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnews_by_month\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32100\\3699512444.py\u001b[0m in \u001b[0;36mclean_month_name\u001b[1;34m(date_text)\u001b[0m\n\u001b[0;32m     10\u001b[0m     }\n\u001b[0;32m     11\u001b[0m     \u001b[0mmonth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'([A-Za-z]+) (\\d{4})'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmonths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myear\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# 读取文件\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Copyright'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "def clean_month_name(date_text):\n",
    "    months = {\n",
    "        \"January\": \"January\", \"February\": \"February\", \"March\": \"March\",\n",
    "        \"April\": \"April\", \"May\": \"May\", \"June\": \"June\",\n",
    "        \"July\": \"July\", \"August\": \"August\", \"September\": \"September\",\n",
    "        \"October\": \"October\", \"November\": \"November\", \"December\": \"December\"\n",
    "    }\n",
    "    month, year = re.search(r'([A-Za-z]+) (\\d{4})', date_text).groups()\n",
    "    return months[month], year\n",
    "\n",
    "# 读取文件\n",
    "with open(\"C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/factiva/Factiva-01July20242121.rtf\", \"r\", encoding=\"latin-1\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "# 准备目录\n",
    "output_dir = 'C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/factiva/News_Split'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 通过日期分割新闻，包括处理跨越月份的新闻\n",
    "pattern = r'(\\d{1,2} [A-Za-z]+ \\d{4})'\n",
    "dates = re.findall(pattern, text)\n",
    "splits = re.split(pattern, text)[1:]  # 第一项可能是非日期前的文本\n",
    "\n",
    "news_by_month = {}\n",
    "for i in range(0, len(splits), 2):\n",
    "    date_text, content = splits[i], splits[i+1]\n",
    "    month, year = clean_month_name(date_text)\n",
    "    month_year_key = f\"{month} {year}\"\n",
    "    if month_year_key not in news_by_month:\n",
    "        news_by_month[month_year_key] = content.strip()\n",
    "    else:\n",
    "        news_by_month[month_year_key] += \"\\n\" + content.strip()\n",
    "\n",
    "# 写入文件\n",
    "for month_year, content in news_by_month.items():\n",
    "    file_name = os.path.join(output_dir, f\"news_{month_year}.txt\")\n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        file.write(content)\n",
    "    print(f\"Saved file: {file_name}\")\n",
    "\n",
    "print(\"所有新闻按月份分割并保存。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40fefc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'january': 'C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/2021_january.txt', 'march': 'C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/2021_march.txt', 'april': 'C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/2021_april.txt', 'june': 'C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/2021_june.txt', 'august': 'C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/2021_august.txt', 'december': 'C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/2021_december.txt'}\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "import re\n",
    "\n",
    "# Function to determine if a string is a date header\n",
    "def is_date(text):\n",
    "    pattern = re.compile(r'\\d{1,2}\\s+\\w+\\s+2021')\n",
    "    return bool(pattern.match(text))\n",
    "\n",
    "# Function to extract news items and categorize them by month\n",
    "def extract_news(doc):\n",
    "    month_news = {}\n",
    "    current_month = None\n",
    "\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        if text and is_date(text):\n",
    "            date_parts = text.split()\n",
    "            current_month = date_parts[1].lower()\n",
    "            if current_month not in month_news:\n",
    "                month_news[current_month] = []\n",
    "        elif text and current_month:\n",
    "            if \"Copyright ©\" not in text and text not in month_news[current_month]:\n",
    "                month_news[current_month].append(text)\n",
    "\n",
    "    return month_news\n",
    "\n",
    "# Load the Word document\n",
    "doc_path =  r'C:\\Users\\22749\\Desktop\\UoG\\Fintech\\Dissertation\\Data\\News\\factiva\\WSJ2021.docx'\n",
    "doc = Document(doc_path)\n",
    "\n",
    "# Extract news data\n",
    "refined_news_by_month = extract_news(doc)\n",
    "\n",
    "# Save news items to separate text files by month\n",
    "output_files = {}\n",
    "\n",
    "for month, contents in refined_news_by_month.items():\n",
    "    filename = f'C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/2021_{month}.txt'\n",
    "    with open(filename, 'w', encoding='utf-8') as file:  # Specify UTF-8 encoding\n",
    "        file.write(\"\\n\\n\".join(contents))\n",
    "\n",
    "    output_files[month] = filename\n",
    "\n",
    "# Output the paths to the saved files\n",
    "print(output_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cd7e200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "import re\n",
    "\n",
    "# Function to determine if a string is a date header\n",
    "def is_date(text):\n",
    "    pattern = re.compile(r'\\d{1,2}\\s+\\w+\\s+202[1-3]')\n",
    "    return bool(pattern.match(text))\n",
    "\n",
    "# Function to extract news items and categorize them by month and year\n",
    "def extract_news(doc):\n",
    "    month_news = {}\n",
    "    current_month = None  # Initialize current_month outside of the loop\n",
    "\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        if text:\n",
    "            date_match = re.match(r'(\\d{1,2})\\s+(\\w+)\\s+(202[1-3])', text)  # Matches day, month, and year\n",
    "            if date_match:\n",
    "                day, month, year = date_match.groups()\n",
    "                month = month.lower()\n",
    "                key = (month, year)  # Use a tuple (month, year) as the dictionary key\n",
    "                if key not in month_news:\n",
    "                    month_news[key] = []\n",
    "                current_month = key\n",
    "            elif current_month and \"Copyright ©\" not in text:\n",
    "                month_news[current_month].append(text)\n",
    "\n",
    "    return month_news\n",
    "\n",
    "# Load the Word document\n",
    "doc_path = r'C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/factiva/Factiva-01July20242049.docx'\n",
    "doc = Document(doc_path)\n",
    "\n",
    "# Extract news data\n",
    "refined_news_by_month_and_year = extract_news(doc)\n",
    "\n",
    "# Save news items to separate text files by month and year, checking if they exist\n",
    "output_files = {}\n",
    "\n",
    "base_directory = 'C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/monthly/'\n",
    "for (month, year), contents in refined_news_by_month_and_year.items():\n",
    "    month = month.capitalize()\n",
    "    filename = f'{base_directory}{month}_{year}.txt'\n",
    "    mode = 'a' if os.path.exists(filename) else 'w'  # Append if exists, otherwise write\n",
    "    with open(filename, mode, encoding='utf-8') as file:\n",
    "        if mode == 'a':  # Add a newline before appending if the file exists\n",
    "            file.write(\"\\n\\n\")\n",
    "        file.write(\"\\n\\n\".join(contents))\n",
    "    output_files[(month, year)] = filename\n",
    "\n",
    "# Output the paths to the saved files\n",
    "print(output_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecfaf4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files created:\n",
      "September_2022: C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/monthly/September_2022.txt\n",
      "June_2020: C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/monthly/June_2020.txt\n",
      "March_2020: C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/monthly/March_2020.txt\n",
      "June_2023: C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/monthly/June_2023.txt\n",
      "March_2022: C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/monthly/March_2022.txt\n",
      "November_2021: C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/monthly/November_2021.txt\n",
      "October_2020: C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/monthly/October_2020.txt\n",
      "June_2021: C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/monthly/June_2021.txt\n",
      "December_2021: C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/monthly/December_2021.txt\n",
      "July_2020: C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/monthly/July_2020.txt\n",
      "September_2021: C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/monthly/September_2021.txt\n",
      "May_2021: C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/monthly/May_2021.txt\n",
      "July_2021: C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/monthly/July_2021.txt\n",
      "June_2022: C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/monthly/June_2022.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "import re\n",
    "\n",
    "def extract_news(doc_path):\n",
    "    # Load the document\n",
    "    doc = Document(doc_path)\n",
    "    \n",
    "    # Regular expression to match dates and categorize news by month and year\n",
    "    date_pattern = re.compile(r'^\\d{1,2} \\w+ \\d{4}')\n",
    "    month_news = {}\n",
    "    current_month = None\n",
    "    current_year = None\n",
    "    \n",
    "    # Iterate through the paragraphs to extract news\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        if text:\n",
    "            date_match = date_pattern.match(text)\n",
    "            if date_match:\n",
    "                # Extract month and year from the date\n",
    "                date_parts = text.split()\n",
    "                current_month = date_parts[1]\n",
    "                current_year = date_parts[2]\n",
    "                month_year_key = f'{current_month}_{current_year}'\n",
    "                if month_year_key not in month_news:\n",
    "                    month_news[month_year_key] = []\n",
    "            elif current_month and current_year:\n",
    "                month_news[month_year_key].append(text)\n",
    "    \n",
    "    return month_news\n",
    "\n",
    "def save_news_by_month(news_dict, base_directory):\n",
    "    if not os.path.exists(base_directory):\n",
    "        os.makedirs(base_directory)\n",
    "    \n",
    "    output_files = {}\n",
    "    for month_year, contents in news_dict.items():\n",
    "        filename = os.path.join(base_directory, f'{month_year}.txt')\n",
    "        # Use 'a' mode for appending instead of 'w' mode which overwrites\n",
    "        with open(filename, 'a', encoding='utf-8') as file:\n",
    "            file.write(\"\\n\\n\" + \"\\n\".join(contents))  # Ensure separation from existing content\n",
    "        output_files[month_year] = filename\n",
    "    \n",
    "    return output_files\n",
    "\n",
    "# Path to the DOCX file\n",
    "doc_path = r'C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/factiva/Factiva-01July20241938.docx'\n",
    "base_directory =  'C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/monthly/'\n",
    "\n",
    "# Extract and save news\n",
    "news_by_month = extract_news(doc_path)\n",
    "output_files = save_news_by_month(news_by_month, base_directory)\n",
    "\n",
    "# Print out the files created\n",
    "print(\"Files created:\")\n",
    "for month_year, filepath in output_files.items():\n",
    "    print(f\"{month_year}: {filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cde0f653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/lexis/202003(290).RTF'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from striprtf.striprtf import rtf_to_text\n",
    "\n",
    "def rtf_to_text_file(rtf_path, text_path):\n",
    "    # 打开 RTF 文件并读取内容\n",
    "    with open(rtf_path, \"r\") as file:\n",
    "        rtf_content = file.read()\n",
    "    \n",
    "    # 转换 RTF 内容为纯文本\n",
    "    text_content = rtf_to_text(rtf_content)\n",
    "    \n",
    "    # 将转换后的纯文本续写到指定的文本文件中\n",
    "    with open(text_path, \"a\") as file:\n",
    "        file.write(text_content)\n",
    "\n",
    "# 示例文件路径\n",
    "rtf_path = r'C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/lexis/202003(290).RTF'\n",
    "text_path = 'C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/monthly/March_2020.txt'\n",
    "\n",
    "# 调用函数\n",
    "rtf_to_text(rtf_path, text_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9f8b041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RTF 文件已成功读取。\n",
      "发生错误: The command `unrtf --text C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/lexis/202003(290).RTF` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import textract\n",
    "\n",
    "def convert_rtf_to_text(rtf_path, output_text_path):\n",
    "    text = textract.process(rtf_path)\n",
    "    with open(output_text_path, 'wb') as f:\n",
    "        f.write(text)\n",
    "\n",
    "def rtf_to_text_file(rtf_path, text_path):\n",
    "    try:\n",
    "        # 打开 RTF 文件并读取内容\n",
    "        with open(rtf_path, \"rb\") as file:  # 使用 \"rb\" 读取二进制模式\n",
    "            rtf_content = file.read()\n",
    "        print(\"RTF 文件已成功读取。\")\n",
    "\n",
    "        # 转换 RTF 内容为纯文本\n",
    "        convert_rtf_to_text(rtf_path, text_path)\n",
    "        print(\"内容转换为纯文本完成。\")\n",
    "\n",
    "        # 将转换后的纯文本续写到指定的文本文件中\n",
    "        with open(text_path, \"a\", encoding='utf-8') as file:  # 使用 UTF-8 编码写入\n",
    "            file.write(text_content)\n",
    "        print(\"内容已写入文本文件。\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"发生错误: {e}\")\n",
    "\n",
    "# 示例文件路径\n",
    "rtf_path = \"C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/lexis/202003(290).RTF\"\n",
    "text_path = \"C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/monthly/March_2020.txt\"\n",
    "\n",
    "# 调用函数\n",
    "rtf_to_text_file(rtf_path, text_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b0e5701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "\n",
    "# 读取doc文件内容\n",
    "def read_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    content = []\n",
    "    for para in doc.paragraphs:\n",
    "        content.append(para.text)\n",
    "    return \"\\n\".join(content)\n",
    "\n",
    "# 将内容续写到text文件中\n",
    "def write_to_text(file_path, content):\n",
    "    with open(file_path, 'a', encoding='utf-8') as file:\n",
    "        file.write(content)\n",
    "\n",
    "# 示例使用\n",
    "docx_file_path = \"C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/lexis/202202(84).docx\"\n",
    "text_file_path = \"C:/Users/22749/Desktop/UoG/Fintech/Dissertation/Data/News/monthly/February_2022.txt\"\n",
    "\n",
    "# 读取doc文件内容\n",
    "doc_content = read_docx(docx_file_path)\n",
    "\n",
    "# 将内容续写到text文件中\n",
    "write_to_text(text_file_path, doc_content)\n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be204a75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
